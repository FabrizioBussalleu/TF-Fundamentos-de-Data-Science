{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b541923c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalaci√≥n de dependencias\n",
    "%pip install pandas numpy matplotlib scikit-learn --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5410306c",
   "metadata": {},
   "source": [
    "# Introducci√≥n\n",
    "Este notebook documenta la aplicaci√≥n de la metodolog√≠a CRISP-DM para comprender el perfil del cliente de Peru_bike, generar conocimiento accionable y apoyar decisiones basadas en datos. A lo largo de las celdas se detalla cada fase del ciclo de vida, desde la comprensi√≥n del negocio hasta la construcci√≥n del modelo de scoring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ee7d0a",
   "metadata": {},
   "source": [
    "# Equipo y roles\n",
    "- **Business Project Sponsor:** _(Completar nombre)_ ‚Äì Define objetivos y valida impacto de negocio.\n",
    "- **Data Scientist:** _(Completar nombre)_ ‚Äì Dise√±a experimentos anal√≠ticos y construye el modelo de scoring.\n",
    "- **Data Engineer:** _(Completar nombre)_ ‚Äì Gestiona la ingesta, limpieza y versionado de datos.\n",
    "- **Data Analyst:** _(Completar nombre)_ ‚Äì Genera insights descriptivos, visualizaciones y conclusiones para los stakeholders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1c8c42",
   "metadata": {},
   "source": [
    "# Gu√≠a de lectura CRISP-DM\n",
    "Cada bloque de c√≥digo corresponde a una fase de CRISP-DM: comprensi√≥n del negocio, comprensi√≥n de los datos, preparaci√≥n, modelado y conclusiones preliminares. Completar este notebook facilita construir el informe PDF requerido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2c4d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF_data.py\n",
    "# Proyecto Bike Buyers - CRISP-DM completo en un solo archivo\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tkinter import Tk, filedialog\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 1. CARGA INTERACTIVA DEL CSV\n",
    "REPO_ROOT = Path(__file__).resolve().parent if \"__file__\" in globals() else Path.cwd()\n",
    "DATA_DIR = REPO_ROOT / \"data\"\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RAW_DATA_CANDIDATES = [DATA_DIR / \"bike_buyers.csv\", REPO_ROOT / \"data.csv\"]\n",
    "CLEAN_DATA_PATH = DATA_DIR / \"bike_buyers_clean.csv\"\n",
    "\n",
    "def cargar_csv_interactivo():\n",
    "    \"\"\"\n",
    "    Carga el dataset bike_buyers.csv intentando primero las rutas versionadas en el repositorio.\n",
    "    Si no se encuentra el archivo, abre un di√°logo interactivo para seleccionarlo manualmente.\n",
    "    \"\"\"\n",
    "    for candidate in RAW_DATA_CANDIDATES:\n",
    "        if candidate.exists():\n",
    "            print(f\"\\n‚úÖ Archivo cargado autom√°ticamente: {candidate}\\n\")\n",
    "            df_loaded = pd.read_csv(candidate)\n",
    "            if candidate != RAW_DATA_CANDIDATES[0]:\n",
    "                df_loaded.to_csv(RAW_DATA_CANDIDATES[0], index=False)\n",
    "                print(f\"üìÅ Copia del dataset original guardada en {RAW_DATA_CANDIDATES[0]}\")\n",
    "            return df_loaded\n",
    "\n",
    "    print(\"Se abrir√° una ventana para que elijas el archivo bike_buyers.csv...\")\n",
    "    root = Tk()\n",
    "    root.withdraw()  # Oculta la ventana principal\n",
    "    root.attributes(\"-topmost\", True)  # La pone delante de todo\n",
    "\n",
    "    ruta = filedialog.askopenfilename(\n",
    "        title=\"Selecciona el archivo bike_buyers.csv\",\n",
    "        filetypes=[(\"CSV files\", \"*.csv\"), (\"Todos los archivos\", \"*.*\")]\n",
    "    )\n",
    "\n",
    "    root.destroy()\n",
    "\n",
    "    if not ruta:\n",
    "        raise SystemExit(\"‚ùå No seleccionaste ning√∫n archivo. Vuelve a ejecutar el programa.\")\n",
    "\n",
    "    print(f\"\\n‚úÖ Archivo seleccionado: {ruta}\\n\")\n",
    "    df_loaded = pd.read_csv(ruta)\n",
    "    df_loaded.to_csv(RAW_DATA_CANDIDATES[0], index=False)\n",
    "    print(f\"üìÅ Dataset versionado en: {RAW_DATA_CANDIDATES[0]}\")\n",
    "    return df_loaded\n",
    "\n",
    "df = cargar_csv_interactivo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bbef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. CARGAR Y LIMPIAR DATA\n",
    "print(\"Primeras filas del dataset:\")\n",
    "print(df.head())\n",
    "print(\"\\nInformaci√≥n general del dataset:\")\n",
    "df.info()\n",
    "print(\"\\nTama√±o del dataset:\", df.shape)\n",
    "\n",
    "missing_summary = df.isna().sum().sort_values(ascending=False)\n",
    "print(\"\\nValores nulos por columna:\")\n",
    "print(missing_summary[missing_summary > 0] if missing_summary.any() else \"No se encontraron nulos.\")\n",
    "\n",
    "duplicate_count = df.duplicated().sum()\n",
    "print(f\"\\nRegistros duplicados detectados: {duplicate_count}\")\n",
    "\n",
    "numeric_summary = df.select_dtypes(include=[np.number]).describe().T\n",
    "print(\"\\nEstad√≠sticos descriptivos de variables num√©ricas:\")\n",
    "print(numeric_summary)\n",
    "\n",
    "# Eliminamos filas con nulos cuando existen y generamos un dataset limpio versionado\n",
    "df_clean = df.dropna().copy()\n",
    "print(\"\\nTama√±o despu√©s de dropna():\", df_clean.shape)\n",
    "\n",
    "df_clean.to_csv(CLEAN_DATA_PATH, index=False)\n",
    "print(f\"\\nüìÅ Dataset limpio guardado en: {CLEAN_DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daeeedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. NUEVAS VARIABLES\n",
    "df_clean[\"Con_hijos\"] = np.where(df_clean[\"Children\"] > 0, \"Si\", \"No\")\n",
    "df_clean[\"Con_vehiculo\"] = np.where(df_clean[\"Cars\"] > 0, \"Si\", \"No\")\n",
    "print(\"Columnas derivadas creadas: Con_hijos, Con_vehiculo\")\n",
    "\n",
    "print(\"\\nFrecuencia Con_hijos:\")\n",
    "print(df_clean[\"Con_hijos\"].value_counts())\n",
    "print(\"\\nFrecuencia Con_vehiculo:\")\n",
    "print(df_clean[\"Con_vehiculo\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6059cc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3a. CONTROL DE CALIDAD (OUTLIERS)\n",
    "numeric_cols = df_clean.select_dtypes(include=[np.number]).columns\n",
    "outlier_report = []\n",
    "for col in numeric_cols:\n",
    "    q1_val = df_clean[col].quantile(0.25)\n",
    "    q3_val = df_clean[col].quantile(0.75)\n",
    "    iqr = q3_val - q1_val\n",
    "    lower_bound = q1_val - 1.5 * iqr\n",
    "    upper_bound = q3_val + 1.5 * iqr\n",
    "    outliers = df_clean[(df_clean[col] < lower_bound) | (df_clean[col] > upper_bound)]\n",
    "    outlier_report.append({\n",
    "        \"variable\": col,\n",
    "        \"outliers\": len(outliers),\n",
    "        \"porcentaje\": (len(outliers) / len(df_clean) * 100) if len(df_clean) else 0\n",
    "    })\n",
    "\n",
    "print(\"\\nResumen de posibles outliers (criterio IQR 1.5):\")\n",
    "for item in outlier_report:\n",
    "    print(f\"- {item['variable']}: {item['outliers']} registros ({item['porcentaje']:.2f}% del total)\")\n",
    "print(\"\\nNo se eliminan outliers autom√°ticamente; su tratamiento depender√° del an√°lisis de negocio.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0587135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. REQUERIMIENTOS (PREGUNTAS)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PREGUNTA 1: Promedio de ingresos seg√∫n si compr√≥ bicicleta\")\n",
    "print(\"=\" * 60)\n",
    "q1 = df_clean.groupby(\"Purchased Bike\")[\"Income\"].mean().sort_values(ascending=False)\n",
    "tabla_q1 = q1.reset_index().rename(columns={\"Purchased Bike\": \"Compr√≥ bicicleta\", \"Income\": \"Ingreso promedio\"})\n",
    "print(tabla_q1.to_string(index=False))\n",
    "plt.figure(figsize=(6, 4))\n",
    "ax = q1.plot(kind=\"bar\", color=\"#1f77b4\")\n",
    "ax.legend([\"Ingreso promedio\"], loc=\"upper left\")\n",
    "plt.title(\"Ingreso promedio por compra de bicicleta\")\n",
    "plt.xlabel(\"Purchased Bike\")\n",
    "plt.ylabel(\"Ingreso promedio\")\n",
    "plt.grid(axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PREGUNTA 2: Promedio de ingresos seg√∫n estado civil\")\n",
    "print(\"=\" * 60)\n",
    "q2 = df_clean.groupby(\"Marital Status\")[\"Income\"].mean().sort_values(ascending=False)\n",
    "tabla_q2 = q2.reset_index().rename(columns={\"Marital Status\": \"Estado civil\", \"Income\": \"Ingreso promedio\"})\n",
    "print(tabla_q2.to_string(index=False))\n",
    "plt.figure(figsize=(6, 4))\n",
    "ax = q2.plot(kind=\"bar\", color=\"#ff7f0e\")\n",
    "ax.legend([\"Ingreso promedio\"], loc=\"upper left\")\n",
    "plt.title(\"Ingreso promedio por estado civil\")\n",
    "plt.xlabel(\"Estado civil\")\n",
    "plt.ylabel(\"Ingreso promedio\")\n",
    "plt.grid(axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PREGUNTA 3: Promedio de hijos seg√∫n nivel educativo (solo con hijos)\")\n",
    "print(\"=\" * 60)\n",
    "q3 = df_clean[df_clean[\"Con_hijos\"] == \"Si\"].groupby(\"Education\")[\"Children\"].mean().sort_values(ascending=False)\n",
    "tabla_q3 = q3.reset_index().rename(columns={\"Education\": \"Nivel educativo\", \"Children\": \"Promedio de hijos\"})\n",
    "print(tabla_q3.to_string(index=False))\n",
    "plt.figure(figsize=(7, 4))\n",
    "ax = q3.plot(kind=\"bar\", color=\"#2ca02c\")\n",
    "ax.legend([\"Promedio de hijos\"], loc=\"upper left\")\n",
    "plt.title(\"Promedio de hijos por nivel educativo (clientes con hijos)\")\n",
    "plt.xlabel(\"Nivel educativo\")\n",
    "plt.ylabel(\"Promedio de hijos\")\n",
    "plt.grid(axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PREGUNTA 4: Promedio de veh√≠culos seg√∫n ocupaci√≥n (solo con veh√≠culo)\")\n",
    "print(\"=\" * 60)\n",
    "q4 = df_clean[df_clean[\"Con_vehiculo\"] == \"Si\"].groupby(\"Occupation\")[\"Cars\"].mean().sort_values(ascending=False)\n",
    "tabla_q4 = q4.reset_index().rename(columns={\"Occupation\": \"Ocupaci√≥n\", \"Cars\": \"Promedio de veh√≠culos\"})\n",
    "print(tabla_q4.to_string(index=False))\n",
    "plt.figure(figsize=(8, 4))\n",
    "ax = q4.plot(kind=\"bar\", color=\"#d62728\")\n",
    "ax.legend([\"Promedio de veh√≠culos\"], loc=\"upper left\")\n",
    "plt.title(\"Promedio de veh√≠culos por ocupaci√≥n (clientes con veh√≠culo)\")\n",
    "plt.xlabel(\"Ocupaci√≥n\")\n",
    "plt.ylabel(\"Promedio de veh√≠culos\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.grid(axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PREGUNTA 5: Promedio de edad seg√∫n si es propietario de vivienda\")\n",
    "print(\"=\" * 60)\n",
    "q5 = df_clean.groupby(\"Home Owner\")[\"Age\"].mean().sort_values(ascending=False)\n",
    "tabla_q5 = q5.reset_index().rename(columns={\"Home Owner\": \"Propietario vivienda\", \"Age\": \"Edad promedio\"})\n",
    "print(tabla_q5.to_string(index=False))\n",
    "plt.figure(figsize=(6, 4))\n",
    "ax = q5.plot(kind=\"bar\", color=\"#9467bd\")\n",
    "ax.legend([\"Edad promedio\"], loc=\"upper left\")\n",
    "plt.title(\"Edad promedio por condici√≥n de propiedad de vivienda\")\n",
    "plt.xlabel(\"Propietario de vivienda\")\n",
    "plt.ylabel(\"Edad promedio\")\n",
    "plt.grid(axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e09a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. MODELADO (SCORING)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODELADO: Regresi√≥n Log√≠stica para predecir 'Purchased Bike'\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "df_model = df_clean.copy()\n",
    "df_model[\"Target\"] = np.where(df_model[\"Purchased Bike\"] == \"Yes\", 1, 0)\n",
    "\n",
    "y = df_model[\"Target\"]\n",
    "X = df_model.drop(columns=[\"Purchased Bike\", \"Target\", \"ID\"])\n",
    "\n",
    "numeric = [\"Income\", \"Children\", \"Cars\", \"Age\"]\n",
    "categorical = [c for c in X.columns if c not in numeric]\n",
    "\n",
    "print(\"\\nVariables num√©ricas:\", numeric)\n",
    "print(\"Variables categ√≥ricas:\", categorical)\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", \"passthrough\", numeric),\n",
    "        (\"cat\", OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\"), categorical)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    (\"prep\", preprocess),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "print(\"\\nResultados del modelo:\")\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"AUC-ROC: {auc:.4f}\")\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f\"ROC (AUC = {auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Curva ROC - Regresi√≥n Log√≠stica\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ace5199",
   "metadata": {},
   "source": [
    "# Conclusiones preliminares\n",
    "- Los ingresos y la tenencia de vivienda muestran diferencias claras entre quienes compran y no compran bicicletas, aportando se√±ales para campa√±as segmentadas.\n",
    "- Las variables derivadas `Con_hijos` y `Con_vehiculo` ayudan a perfilar mejor los grupos de mayor propensi√≥n, facilitando acciones de cross-sell.\n",
    "- El modelo de regresi√≥n log√≠stica presenta m√©tricas s√≥lidas (accuracy y AUC), habilitando un scoring inicial para priorizar oportunidades comerciales.\n",
    "- Pr√≥ximos pasos: validar el modelo con stakeholders, ajustar umbrales seg√∫n la capacidad comercial y documentar el proceso en el informe PDF final."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
